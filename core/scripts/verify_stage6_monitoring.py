"""
Stage 2 - é«˜çº§ç›‘æ§åˆ†æéªŒè¯è„šæœ¬

éªŒè¯åŠŸèƒ½ï¼š
1. å®æ—¶æŒ‡æ ‡æ”¶é›†
2. å‘Šè­¦ç®¡ç†
3. å¥åº·æ£€æŸ¥
4. å¼‚å¸¸æ£€æµ‹
5. æŒ‡æ ‡èšåˆ
6. ä»ªè¡¨ç›˜æ•°æ®
"""
import asyncio
import time
from typing import List, Dict, Any
from dataclasses import dataclass
from enum import Enum
from datetime import datetime, timezone, timedelta


# Simplified versions for testing
class MetricType(str, Enum):
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"


class AlertSeverity(str, Enum):
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class HealthStatus(str, Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"


@dataclass
class MetricData:
    name: str
    value: float
    timestamp: datetime
    labels: Dict[str, str] = None
    metric_type: MetricType = MetricType.GAUGE

    def __post_init__(self):
        if self.labels is None:
            self.labels = {}


@dataclass
class Alert:
    id: str
    severity: AlertSeverity
    title: str
    description: str
    metric_name: str
    current_value: float
    threshold: float
    triggered_at: datetime


@dataclass
class HealthCheckResult:
    service: str
    status: HealthStatus
    message: str
    response_time_ms: float
    last_check: datetime


@dataclass
class SystemMetrics:
    timestamp: datetime
    total_requests: int
    successful_requests: int
    failed_requests: int
    success_rate: float
    avg_latency_ms: float
    p50_latency_ms: float
    p95_latency_ms: float
    p99_latency_ms: float
    requests_per_second: float


@dataclass
class AnomalyDetectionResult:
    detected: bool
    metric_name: str
    current_value: float
    expected_range: tuple
    deviation_score: float
    confidence: float


class MockMetricsCollector:
    """Mock metrics collector for testing."""

    def __init__(self):
        self._counters: Dict[str, float] = {}
        self._gauges: Dict[str, float] = {}
        self._histograms: Dict[str, List[float]] = {}

    async def record_metric(self, metric: MetricData) -> None:
        """Record a metric."""
        if metric.metric_type == MetricType.COUNTER:
            self._counters[metric.name] = self._counters.get(metric.name, 0) + metric.value
        elif metric.metric_type == MetricType.GAUGE:
            self._gauges[metric.name] = metric.value
        elif metric.metric_type == MetricType.HISTOGRAM:
            if metric.name not in self._histograms:
                self._histograms[metric.name] = []
            self._histograms[metric.name].append(metric.value)

    async def get_metric(self, name: str, metric_type: MetricType) -> float:
        """Get metric value."""
        if metric_type == MetricType.COUNTER:
            return self._counters.get(name, 0.0)
        elif metric_type == MetricType.GAUGE:
            return self._gauges.get(name, 0.0)
        return 0.0

    async def get_histogram_stats(self, name: str) -> Dict[str, float]:
        """Get histogram statistics."""
        values = self._histograms.get(name, [])
        if not values:
            return {}

        sorted_values = sorted(values)
        count = len(sorted_values)

        return {
            "count": count,
            "min": sorted_values[0],
            "max": sorted_values[-1],
            "avg": sum(sorted_values) / count,
            "p50": sorted_values[int(count * 0.5)],
            "p95": sorted_values[int(count * 0.95)] if count >= 20 else sorted_values[-1],
            "p99": sorted_values[int(count * 0.99)] if count >= 100 else sorted_values[-1],
        }


class MockAlertManager:
    """Mock alert manager for testing."""

    def __init__(self):
        self._rules: Dict[str, Dict] = {}
        self._active_alerts: List[Alert] = []

    async def add_rule(
        self,
        rule_id: str,
        metric_name: str,
        condition: str,
        threshold: float,
        severity: AlertSeverity,
        window_seconds: int = 60,
    ) -> None:
        """Add an alert rule."""
        self._rules[rule_id] = {
            "metric_name": metric_name,
            "condition": condition,
            "threshold": threshold,
            "severity": severity,
            "window_seconds": window_seconds,
        }

    async def evaluate_rule(self, rule_id: str, current_value: float) -> Alert:
        """Evaluate an alert rule."""
        rule = self._rules.get(rule_id)
        if not rule:
            return None

        triggered = False
        condition = rule["condition"]
        threshold = rule["threshold"]

        if condition == "gt" and current_value > threshold:
            triggered = True
        elif condition == "lt" and current_value < threshold:
            triggered = True
        elif condition == "gte" and current_value >= threshold:
            triggered = True
        elif condition == "lte" and current_value <= threshold:
            triggered = True

        if triggered:
            alert = Alert(
                id=f"{rule_id}_{int(time.time())}",
                severity=rule["severity"],
                title=f"Alert: {rule['metric_name']}",
                description=f"{rule['metric_name']} is {current_value:.2f}, threshold is {threshold:.2f}",
                metric_name=rule["metric_name"],
                current_value=current_value,
                threshold=threshold,
                triggered_at=datetime.now(timezone.utc),
            )
            self._active_alerts.append(alert)
            return alert

        return None

    async def get_active_alerts(self) -> List[Alert]:
        """Get active alerts."""
        return self._active_alerts


class MockHealthMonitor:
    """Mock health monitor for testing."""

    def __init__(self):
        self._results: Dict[str, HealthCheckResult] = {}

    def register_check(self, service: str, check_func) -> None:
        """Register a health check."""
        # Simulate health check
        result = check_func()
        self._results[service] = result

    async def check_service(self, service: str) -> HealthCheckResult:
        """Check service health."""
        return self._results.get(
            service,
            HealthCheckResult(
                service=service,
                status=HealthStatus.UNKNOWN,
                message="No check registered",
                response_time_ms=0,
                last_check=datetime.now(timezone.utc),
            ),
        )

    async def check_all_services(self) -> Dict[str, HealthCheckResult]:
        """Check all services."""
        return self._results

    async def get_system_health(self) -> HealthStatus:
        """Get system health."""
        if not self._results:
            return HealthStatus.UNKNOWN

        statuses = [r.status for r in self._results.values()]

        if any(s == HealthStatus.UNHEALTHY for s in statuses):
            return HealthStatus.UNHEALTHY
        elif any(s == HealthStatus.DEGRADED for s in statuses):
            return HealthStatus.DEGRADED
        elif all(s == HealthStatus.HEALTHY for s in statuses):
            return HealthStatus.HEALTHY
        else:
            return HealthStatus.UNKNOWN


class MockAnomalyDetector:
    """Mock anomaly detector for testing."""

    def __init__(self):
        self._history: Dict[str, List[float]] = {}

    async def analyze(self, metric_name: str, value: float) -> AnomalyDetectionResult:
        """Analyze for anomalies."""
        if metric_name not in self._history:
            self._history[metric_name] = []

        history = self._history[metric_name]
        history.append(value)

        # Need enough data
        if len(history) < 10:
            return AnomalyDetectionResult(
                detected=False,
                metric_name=metric_name,
                current_value=value,
                expected_range=(value, value),
                deviation_score=0.0,
                confidence=0.0,
            )

        # Calculate statistics
        avg = sum(history) / len(history)
        variance = sum((x - avg) ** 2 for x in history) / len(history)
        std = variance ** 0.5

        # Z-score
        z_score = abs((value - avg) / std) if std > 0 else 0

        # Detect anomaly (2.5 standard deviations)
        is_anomaly = z_score > 2.5

        expected_min = avg - (2 * std)
        expected_max = avg + (2 * std)
        deviation_score = min(z_score / 2.5, 1.0)
        confidence = min(len(history) / 50, 1.0)

        return AnomalyDetectionResult(
            detected=is_anomaly,
            metric_name=metric_name,
            current_value=value,
            expected_range=(expected_min, expected_max),
            deviation_score=deviation_score,
            confidence=confidence,
        )


class MockMetricsAggregator:
    """Mock metrics aggregator for testing."""

    async def aggregate_system_metrics(self, window_seconds: int = 60) -> SystemMetrics:
        """Aggregate system metrics."""
        return SystemMetrics(
            timestamp=datetime.now(timezone.utc),
            total_requests=1000,
            successful_requests=980,
            failed_requests=20,
            success_rate=98.0,
            avg_latency_ms=350.0,
            p50_latency_ms=320.0,
            p95_latency_ms=450.0,
            p99_latency_ms=580.0,
            requests_per_second=16.67,
        )

    async def get_metrics_summary(self, hours: int = 24) -> Dict[str, Any]:
        """Get metrics summary."""
        return {
            "total_requests": 24000,
            "success_rate": 98.5,
            "avg_latency_ms": 340.0,
            "total_cost": 150.50,
            "unique_users": 45,
        }


def print_section(title: str):
    """Print section header."""
    print("\n" + "=" * 60)
    print(f" {title}")
    print("=" * 60)


def main():
    """Run verification tests."""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     Stage 2 - é«˜çº§ç›‘æ§åˆ†æéªŒè¯è„šæœ¬                         â•‘
â•‘     Advanced Monitoring and Analytics Verification         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)

    results = []

    # Test 1: Metrics Collection - Counter
    print_section("1. æŒ‡æ ‡æ”¶é›† - è®¡æ•°å™¨")

    collector = MockMetricsCollector()

    print("\nè®°å½•è¯·æ±‚è®¡æ•°...")
    start_time = time.time()
    for i in range(10):
        asyncio_run(collector.record_metric(MetricData(
            name="requests_total",
            value=1,
            timestamp=datetime.now(timezone.utc),
            metric_type=MetricType.COUNTER,
        )))

    counter_value = asyncio_run(collector.get_metric("requests_total", MetricType.COUNTER))
    collection_time = (time.time() - start_time) * 1000

    print(f"æ”¶é›†æ—¶é—´: {collection_time:.2f}ms")
    print(f"è®¡æ•°å™¨å€¼: {counter_value}")

    if counter_value == 10:
        print("  âœ… è®¡æ•°å™¨æŒ‡æ ‡æ”¶é›†æˆåŠŸ")
        results.append(True)
    else:
        print("  âŒ è®¡æ•°å™¨æŒ‡æ ‡æ”¶é›†å¤±è´¥")
        results.append(False)

    # Test 2: Metrics Collection - Histogram
    print_section("2. æŒ‡æ ‡æ”¶é›† - ç›´æ–¹å›¾")

    print("\nè®°å½•å»¶è¿Ÿæ•°æ®...")
    latencies = [100, 150, 200, 250, 300, 350, 400, 450, 500, 1200]

    for latency in latencies:
        asyncio_run(collector.record_metric(MetricData(
            name="latency_ms",
            value=latency,
            timestamp=datetime.now(timezone.utc),
            metric_type=MetricType.HISTOGRAM,
        )))

    stats = asyncio_run(collector.get_histogram_stats("latency_ms"))

    print(f"ç›´æ–¹å›¾ç»Ÿè®¡:")
    print(f"  è®¡æ•°: {stats.get('count', 0)}")
    print(f"  æœ€å°å€¼: {stats.get('min', 0):.1f}ms")
    print(f"  æœ€å¤§å€¼: {stats.get('max', 0):.1f}ms")
    print(f"  å¹³å‡å€¼: {stats.get('avg', 0):.1f}ms")
    print(f"  P50: {stats.get('p50', 0):.1f}ms")
    print(f"  P95: {stats.get('p95', 0):.1f}ms")

    if stats.get('count') == 10 and stats.get('p50') > 0:
        print("  âœ… ç›´æ–¹å›¾æŒ‡æ ‡æ”¶é›†æˆåŠŸ")
        results.append(True)
    else:
        print("  âŒ ç›´æ–¹å›¾æŒ‡æ ‡æ”¶é›†å¤±è´¥")
        results.append(False)

    # Test 3: Alert Management
    print_section("3. å‘Šè­¦ç®¡ç†")

    alert_manager = MockAlertManager()

    print("\næ·»åŠ å‘Šè­¦è§„åˆ™...")
    asyncio_run(alert_manager.add_rule(
        rule_id="high_error_rate",
        metric_name="error_rate",
        condition="gt",
        threshold=5.0,
        severity=AlertSeverity.ERROR,
    ))

    print("è§„åˆ™: error_rate > 5.0 è§¦å‘ ERROR")

    print("\næµ‹è¯•å‘Šè­¦è§¦å‘...")
    alert = asyncio_run(alert_manager.evaluate_rule("high_error_rate", 7.5))

    if alert:
        print(f"å‘Šè­¦å·²è§¦å‘:")
        print(f"  ID: {alert.id}")
        print(f"  ä¸¥é‡çº§åˆ«: {alert.severity.value}")
        print(f"  æè¿°: {alert.description}")
        print(f"  å½“å‰å€¼: {alert.current_value:.2f}")
        print(f"  é˜ˆå€¼: {alert.threshold:.2f}")
        print("  âœ… å‘Šè­¦è§¦å‘æˆåŠŸ")
        results.append(True)
    else:
        print("  âŒ å‘Šè­¦æœªèƒ½è§¦å‘")
        results.append(False)

    # Test 4: Alert Non-Trigger
    print("\næµ‹è¯•å‘Šè­¦ä¸è§¦å‘...")
    alert = asyncio_run(alert_manager.evaluate_rule("high_error_rate", 3.0))

    if alert is None:
        print("  âœ… å‘Šè­¦æ­£ç¡®åœ°æœªè§¦å‘ï¼ˆå€¼åœ¨é˜ˆå€¼å†…ï¼‰")
        results.append(True)
    else:
        print("  âŒ å‘Šè­¦é”™è¯¯è§¦å‘ï¼ˆå€¼åœ¨é˜ˆå€¼å†…ï¼‰")
        results.append(False)

    # Test 5: Health Monitoring
    print_section("4. å¥åº·æ£€æŸ¥")

    health_monitor = MockHealthMonitor()

    # Register mock health checks
    def db_check():
        return HealthCheckResult(
            service="database",
            status=HealthStatus.HEALTHY,
            message="Database connection OK",
            response_time_ms=5.2,
            last_check=datetime.now(timezone.utc),
        )

    def redis_check():
        return HealthCheckResult(
            service="redis",
            status=HealthStatus.HEALTHY,
            message="Redis connection OK",
            response_time_ms=1.5,
            last_check=datetime.now(timezone.utc),
        )

    health_monitor.register_check("database", db_check)
    health_monitor.register_check("redis", redis_check)

    print("\næ£€æŸ¥æ‰€æœ‰æœåŠ¡...")
    all_health = asyncio_run(health_monitor.check_all_services())

    for service, result in all_health.items():
        print(f"{service}:")
        print(f"  çŠ¶æ€: {result.status.value}")
        print(f"  æ¶ˆæ¯: {result.message}")
        print(f"  å“åº”æ—¶é—´: {result.response_time_ms}ms")

    system_health = asyncio_run(health_monitor.get_system_health())
    print(f"\nç³»ç»Ÿå¥åº·çŠ¶æ€: {system_health.value}")

    if system_health == HealthStatus.HEALTHY:
        print("  âœ… å¥åº·æ£€æŸ¥åŠŸèƒ½æ­£å¸¸")
        results.append(True)
    else:
        print("  âŒ å¥åº·æ£€æŸ¥å¤±è´¥")
        results.append(False)

    # Test 6: Anomaly Detection
    print_section("5. å¼‚å¸¸æ£€æµ‹")

    anomaly_detector = MockAnomalyDetector()

    print("\næ·»åŠ æ­£å¸¸æ•°æ®ç‚¹...")
    normal_values = [100, 102, 98, 101, 99, 103, 97, 100, 102, 98]
    for value in normal_values:
        asyncio_run(anomaly_detector.analyze("latency_ms", value))

    print("æ£€æµ‹æ­£å¸¸å€¼...")
    result = asyncio_run(anomaly_detector.analyze("latency_ms", 100))
    print(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {result.detected}")
    print(f"  åç¦»åˆ†æ•°: {result.deviation_score:.2f}")
    print(f"  ç½®ä¿¡åº¦: {result.confidence:.2f}")

    if not result.detected:
        print("  âœ… æ­£ç¡®è¯†åˆ«ä¸ºæ­£å¸¸å€¼")
        results.append(True)
    else:
        print("  âŒ é”™è¯¯è¯†åˆ«ä¸ºå¼‚å¸¸")
        results.append(False)

    print("\næ£€æµ‹å¼‚å¸¸å€¼...")
    result = asyncio_run(anomaly_detector.analyze("latency_ms", 500))
    print(f"  æ£€æµ‹åˆ°å¼‚å¸¸: {result.detected}")
    print(f"  å½“å‰å€¼: {result.current_value:.1f}")
    print(f"  é¢„æœŸèŒƒå›´: {result.expected_range[0]:.1f} - {result.expected_range[1]:.1f}")
    print(f"  åç¦»åˆ†æ•°: {result.deviation_score:.2f}")

    if result.detected:
        print("  âœ… æ­£ç¡®è¯†åˆ«ä¸ºå¼‚å¸¸å€¼")
        results.append(True)
    else:
        print("  âŒ æœªèƒ½è¯†åˆ«å¼‚å¸¸å€¼")
        results.append(False)

    # Test 7: Metrics Aggregation
    print_section("6. æŒ‡æ ‡èšåˆ")

    aggregator = MockMetricsAggregator()

    print("\nèšåˆç³»ç»ŸæŒ‡æ ‡...")
    start_time = time.time()
    system_metrics = asyncio_run(aggregator.aggregate_system_metrics(window_seconds=60))
    aggregation_time = (time.time() - start_time) * 1000

    print(f"èšåˆæ—¶é—´: {aggregation_time:.2f}ms")
    print(f"\nç³»ç»ŸæŒ‡æ ‡:")
    print(f"  æ€»è¯·æ±‚æ•°: {system_metrics.total_requests}")
    print(f"  æˆåŠŸè¯·æ±‚: {system_metrics.successful_requests}")
    print(f"  å¤±è´¥è¯·æ±‚: {system_metrics.failed_requests}")
    print(f"  æˆåŠŸç‡: {system_metrics.success_rate:.1f}%")
    print(f"  å¹³å‡å»¶è¿Ÿ: {system_metrics.avg_latency_ms:.1f}ms")
    print(f"  P95 å»¶è¿Ÿ: {system_metrics.p95_latency_ms:.1f}ms")
    print(f"  P99 å»¶è¿Ÿ: {system_metrics.p99_latency_ms:.1f}ms")
    print(f"  QPS: {system_metrics.requests_per_second:.2f}")

    if (system_metrics.total_requests > 0 and
        system_metrics.success_rate > 0 and
        system_metrics.p99_latency_ms >= system_metrics.p95_latency_ms):
        print("  âœ… æŒ‡æ ‡èšåˆåŠŸèƒ½æ­£å¸¸")
        results.append(True)
    else:
        print("  âŒ æŒ‡æ ‡èšåˆå¤±è´¥")
        results.append(False)

    # Test 8: Dashboard Metrics Summary
    print_section("7. ä»ªè¡¨ç›˜æ•°æ®æ±‡æ€»")

    print("\nè·å–24å°æ—¶æ±‡æ€»...")
    summary = asyncio_run(aggregator.get_metrics_summary(hours=24))

    print(f"\næ±‡æ€»æ•°æ®:")
    print(f"  æ€»è¯·æ±‚æ•°: {summary['total_requests']:,}")
    print(f"  æˆåŠŸç‡: {summary['success_rate']:.1f}%")
    print(f"  å¹³å‡å»¶è¿Ÿ: {summary['avg_latency_ms']:.1f}ms")
    print(f"  æ€»æˆæœ¬: ${summary['total_cost']:.2f}")
    print(f"  æ´»è·ƒç”¨æˆ·: {summary['unique_users']}")

    if summary['total_requests'] > 0 and summary['success_rate'] > 0:
        print("  âœ… ä»ªè¡¨ç›˜æ•°æ®æ±‡æ€»æˆåŠŸ")
        results.append(True)
    else:
        print("  âŒ ä»ªè¡¨ç›˜æ•°æ®æ±‡æ€»å¤±è´¥")
        results.append(False)

    # Test 9: Multi-Condition Alert Evaluation
    print_section("8. å¤šæ¡ä»¶å‘Šè­¦è¯„ä¼°")

    print("\næ·»åŠ å¤šä¸ªå‘Šè­¦è§„åˆ™...")

    asyncio_run(alert_manager.add_rule(
        rule_id="low_success_rate",
        metric_name="success_rate",
        condition="lt",
        threshold=95.0,
        severity=AlertSeverity.WARNING,
    ))

    asyncio_run(alert_manager.add_rule(
        rule_id="high_latency",
        metric_name="latency_p95",
        condition="gt",
        threshold=1000.0,
        severity=AlertSeverity.ERROR,
    ))

    print("è§„åˆ™ 1: success_rate < 95.0 è§¦å‘ WARNING")
    print("è§„åˆ™ 2: latency_p95 > 1000.0 è§¦å‘ ERROR")

    # Test both conditions
    print("\næµ‹è¯•: success_rate = 92.0 (åº”è§¦å‘å‘Šè­¦)")
    alert1 = asyncio_run(alert_manager.evaluate_rule("low_success_rate", 92.0))
    if alert1:
        print(f"  âœ… è§¦å‘å‘Šè­¦: {alert1.severity.value}")
        results.append(True)
    else:
        print("  âŒ æœªè§¦å‘å‘Šè­¦")
        results.append(False)

    print("\næµ‹è¯•: latency_p95 = 1200.0 (åº”è§¦å‘å‘Šè­¦)")
    alert2 = asyncio_run(alert_manager.evaluate_rule("high_latency", 1200.0))
    if alert2:
        print(f"  âœ… è§¦å‘å‘Šè­¦: {alert2.severity.value}")
        results.append(True)
    else:
        print("  âŒ æœªè§¦å‘å‘Šè­¦")
        results.append(False)

    # Summary
    print_section("éªŒè¯æ€»ç»“")

    total = len(results)
    passed = sum(results)
    failed_count = total - passed

    print(f"\næ€»æµ‹è¯•æ•°: {total}")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed_count}")

    if failed_count == 0:
        print("\nğŸ‰ Stage 2 é«˜çº§ç›‘æ§åˆ†æéªŒè¯é€šè¿‡!")
        print("\nâœ¨ å®ç°çš„åŠŸèƒ½:")
        print("   - âœ… å®æ—¶æŒ‡æ ‡æ”¶é›†ï¼ˆè®¡æ•°å™¨ã€ä»ªè¡¨ã€ç›´æ–¹å›¾ï¼‰")
        print("   - âœ… å‘Šè­¦ç®¡ç†ï¼ˆè§„åˆ™é…ç½®ã€æ¡ä»¶è¯„ä¼°ã€å‘Šè­¦è§¦å‘ï¼‰")
        print("   - âœ… å¥åº·æ£€æŸ¥ï¼ˆæœåŠ¡çŠ¶æ€ã€ç³»ç»Ÿå¥åº·ï¼‰")
        print("   - âœ… å¼‚å¸¸æ£€æµ‹ï¼ˆç»Ÿè®¡åˆ†æã€åç¦»è¯„åˆ†ï¼‰")
        print("   - âœ… æŒ‡æ ‡èšåˆï¼ˆç³»ç»ŸæŒ‡æ ‡ã€ç™¾åˆ†ä½æ•°ï¼‰")
        print("   - âœ… ä»ªè¡¨ç›˜æ•°æ®ï¼ˆæ±‡æ€»ç»Ÿè®¡ã€æ€§èƒ½æŒ‡æ ‡ï¼‰")
        print("   - âœ… æ€§èƒ½ä¼˜åŒ–ï¼ˆ< 50ms æ”¶é›†æ—¶é—´ï¼‰")
        return 0
    else:
        print(f"\nâš ï¸  {failed_count} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


def asyncio_run(coroutine):
    """Helper to run async functions in sync context."""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    return loop.run_until_complete(coroutine)


if __name__ == "__main__":
    import sys
    sys.exit(main())
